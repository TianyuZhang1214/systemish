/*******************************************************************
  This file has been automatically generated by ispc
  DO NOT EDIT THIS FILE DIRECTLY
 *******************************************************************/

/* Provide Declarations */
#include <stdarg.h>
#include <setjmp.h>
#include <limits.h>
#include <stdlib.h>
#ifdef _MSC_VER
  #define NOMINMAX
  #include <windows.h>
#endif // _MSC_VER
#include <stdlib.h>
#include <stdint.h>
/* get a declaration for alloca */
#ifdef _MSC_VER
  #include <malloc.h>
  #define alloca _alloca
#else
  #include <alloca.h>
#endif

#undef ISPC_FAST_MATH
#include "generic-16.h"

/* Basic Library Function Declarations */
extern "C" {
int puts(unsigned char *);
unsigned int putchar(unsigned int);
int fflush(void *);
int printf(const unsigned char *, ...);
uint8_t *memcpy(uint8_t *, uint8_t *, uint64_t );
uint8_t *memset(uint8_t *, uint8_t, uint64_t );
void memset_pattern16(void *, const void *, uint64_t );
}

#ifndef __GNUC__  /* Can only support "linkonce" vars with GCC */
#define __attribute__(X)
#endif

#if defined(__GNUC__) && defined(__APPLE_CC__)
#define __EXTERNAL_WEAK__ __attribute__((weak_import))
#elif defined(__GNUC__)
#define __EXTERNAL_WEAK__ __attribute__((weak))
#else
#define __EXTERNAL_WEAK__
#endif

#if defined(__GNUC__) && defined(__APPLE_CC__)
#define __ATTRIBUTE_WEAK__
#elif defined(__GNUC__)
#define __ATTRIBUTE_WEAK__ __attribute__((weak))
#else
#define __ATTRIBUTE_WEAK__
#endif

#if defined(__GNUC__)
#define __HIDDEN__ __attribute__((visibility("hidden")))
#endif

#if (defined(__GNUC__) || defined(__clang__)) && !defined(__INTEL_COMPILER)
#define LLVM_NAN(NanStr)   __builtin_nan(NanStr)   /* Double */
#define LLVM_NANF(NanStr)  __builtin_nanf(NanStr)  /* Float */
#define LLVM_NANS(NanStr)  __builtin_nans(NanStr)  /* Double */
#define LLVM_NANSF(NanStr) __builtin_nansf(NanStr) /* Float */
#define LLVM_INF           __builtin_inf()         /* Double */
#define LLVM_INFF          __builtin_inff()        /* Float */
//#define LLVM_PREFETCH(addr,rw,locality) __builtin_prefetch(addr,rw,locality)
//#define __ATTRIBUTE_CTOR__ __attribute__((constructor))
//#define __ATTRIBUTE_DTOR__ __attribute__((destructor))
#elif defined(_MSC_VER) || defined(__INTEL_COMPILER)
#include <limits>
#define LLVM_NAN(NanStr)   std::numeric_limits<double>::quiet_NaN()
#define LLVM_NANF(NanStr)  std::numeric_limits<float>::quiet_NaN()
#define LLVM_NANS(NanStr)  std::numeric_limits<double>::signaling_NaN()
#define LLVM_NANSF(NanStr) std::numeric_limits<float>::signaling_NaN()
#define LLVM_INF           std::numeric_limits<double>::infinity()
#define LLVM_INFF          std::numeric_limits<float>::infinity()
//#define LLVM_PREFETCH(addr,rw,locality)            /* PREFETCH */
//#define __ATTRIBUTE_CTOR__
//#define __ATTRIBUTE_DTOR__
#else
#error "Not MSVC, clang, or g++?"
#endif

#if (defined(__GNUC__) || defined(__clang__))
#define LLVM_ASM(X) __asm(X)
#endif

#if defined(__clang__) || defined(__INTEL_COMPILER) || (__GNUC__ < 4) /* Old GCCs, or compilers not GCC */ 
#define __builtin_stack_save() 0   /* not implemented */
#define __builtin_stack_restore(X) /* noop */
#endif

#define CODE_FOR_MAIN() /* Any target-specific code for main()*/

#ifndef __cplusplus
typedef unsigned char bool;
#endif


/* Support for floating point constants */
typedef uint64_t ConstantDoubleTy;
typedef uint32_t ConstantFloatTy;
typedef struct { unsigned long long f1; unsigned short f2; unsigned short pad[3]; } ConstantFP80Ty;
typedef struct { uint64_t f1, f2; } ConstantFP128Ty;


/* Global Declarations */


/* Helper union for bitcasts */
typedef union {
  unsigned int Int32;
  unsigned long long Int64;
  float Float;
  double Double;
} llvmBitCastUnion;

/* Function Declarations */
extern "C" {
void simple___un_3C_uni_3E_un_3C_uni_3E_uni(uint32_t *data_arr_, uint32_t *pkt_arr_, uint32_t base_index_, __vec16_i1 __mask_);
void simple(uint32_t *data_arr_, uint32_t *pkt_arr_, uint32_t base_index_);
}



/* Function Bodies */
template <typename A, typename B> static inline int llvm_fcmp_ord(A X, B Y) { return X == X && Y == Y; }
template <typename A, typename B> static inline int llvm_fcmp_uno(A X, B Y) { return X != X || Y != Y; }
template <typename A, typename B> static inline int llvm_fcmp_ueq(A X, B Y) { return X == Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_une(A X, B Y) { return X != Y; }
template <typename A, typename B> static inline int llvm_fcmp_ult(A X, B Y) { return X <  Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_ugt(A X, B Y) { return X >  Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_ule(A X, B Y) { return X <= Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_uge(A X, B Y) { return X >= Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_oeq(A X, B Y) { return X == Y ; }
template <typename A, typename B> static inline int llvm_fcmp_one(A X, B Y) { return X != Y && llvm_fcmp_ord(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_olt(A X, B Y) { return X <  Y ; }
template <typename A, typename B> static inline int llvm_fcmp_ogt(A X, B Y) { return X >  Y ; }
template <typename A, typename B> static inline int llvm_fcmp_ole(A X, B Y) { return X <= Y ; }
template <typename A, typename B> static inline int llvm_fcmp_oge(A X, B Y) { return X >= Y ; }
template <typename A> A *Memset(A *ptr, int count, size_t len) { return (A *)memset(ptr, count, len); }

static const int32_t __attribute__ ((aligned(64))) VectorConstant0[] = { 0u, 1u, 2u, 3u, 4u, 5u, 6u, 7u, 8u, 9u, 10u, 11u, 12u, 13u, 14u, 15u,  };

void simple___un_3C_uni_3E_un_3C_uni_3E_uni(uint32_t *data_arr_, uint32_t *pkt_arr_, uint32_t base_index_, __vec16_i1 __mask_) {
  bool internal_mask_26_function_mask32_any208_;
  uint8_t *ptr_;
  __vec16_i32 (*ptrcast_);
  __vec16_i1 oldMask_26_test211_2e_us_;
  __vec16_i1 oldMask_26_test211_2e_us___PHI;
  __vec16_i32 j_2e_0210_2e_us_;
  __vec16_i32 j_2e_0210_2e_us___PHI;
  __vec16_i32 v1_2e_i201209_2e_us_;
  __vec16_i32 v1_2e_i201209_2e_us___PHI;
  __vec16_i32 ptr_masked_load_2e_us_;
  bool internal_mask_26_function_mask56_any204_2e_us_;
  __vec16_i32 v1_2e_i202_2e_lcssa_2e_us_;
  __vec16_i32 v1_2e_i202_2e_lcssa_2e_us___PHI;
  __vec16_i32 j_load75_plus1_2e_us_;
  __vec16_i1 oldMask_26_test_2e_us_and_mask_;
  bool internal_mask_26_function_mask32_any_2e_us_;
  __vec16_i1 oldMask_26_test52207_2e_us_;
  __vec16_i1 oldMask_26_test52207_2e_us___PHI;
  __vec16_i32 k_2e_0206_2e_us_;
  __vec16_i32 k_2e_0206_2e_us___PHI;
  __vec16_i32 v1_2e_i202205_2e_us_;
  __vec16_i32 v1_2e_i202205_2e_us___PHI;
  __vec16_i32 v1_2e_i_2e_us_;
  __vec16_i32 k_load67_plus1_2e_us_;
  __vec16_i1 oldMask_26_test52_2e_us_and_mask_;
  bool internal_mask_26_function_mask56_any_2e_us_;
  __vec16_i32 base_index_smear_;
  __vec16_i32 data_arr_load_offset_load193_2e_us_;

  internal_mask_26_function_mask32_any208_ = ((__any(__smear_i1<__vec16_i1>(1)))&1);
  ptr_ = (&(((uint8_t *)pkt_arr_))[((int64_t )(((int64_t )(int32_t )(base_index_ << 2u))))]);
  ptrcast_ = ((__vec16_i32 (*))ptr_);
  if (internal_mask_26_function_mask32_any208_) {
    goto for_loop_2e_lr_2e_ph_2e_us_label;
  } else {
    goto foreach_reset_label;
  }

  do {     /* Syntactic loop 'for_loop.us' to make GCC happy */
for_loop_2e_us_label: {
  oldMask_26_test211_2e_us_ = oldMask_26_test211_2e_us___PHI;
  j_2e_0210_2e_us_ = j_2e_0210_2e_us___PHI;
  v1_2e_i201209_2e_us_ = v1_2e_i201209_2e_us___PHI;
  ptr_masked_load_2e_us_ = __masked_load_i32(ptr_, oldMask_26_test211_2e_us_);
  __masked_store_i32(ptrcast_, (__add(ptr_masked_load_2e_us_, v1_2e_i201209_2e_us_)), oldMask_26_test211_2e_us_);
  internal_mask_26_function_mask56_any204_2e_us_ = ((__any(oldMask_26_test211_2e_us_))&1);
  if (internal_mask_26_function_mask56_any204_2e_us_) {
    oldMask_26_test52207_2e_us___PHI = oldMask_26_test211_2e_us_;   /* for PHI node */
    k_2e_0206_2e_us___PHI = __setzero_i32<__vec16_i32>();   /* for PHI node */
    v1_2e_i202205_2e_us___PHI = v1_2e_i201209_2e_us_;   /* for PHI node */
    goto for_loop46_2e_us_label;
  } else {
    v1_2e_i202_2e_lcssa_2e_us___PHI = v1_2e_i201209_2e_us_;   /* for PHI node */
    goto for_exit47_2e_us_label;
  }

}
  do {     /* Syntactic loop 'for_loop46.us' to make GCC happy */
for_loop46_2e_us_label: {
  oldMask_26_test52207_2e_us_ = oldMask_26_test52207_2e_us___PHI;
  k_2e_0206_2e_us_ = k_2e_0206_2e_us___PHI;
  v1_2e_i202205_2e_us_ = v1_2e_i202205_2e_us___PHI;
  v1_2e_i_2e_us_ = __select(oldMask_26_test52207_2e_us_, (__and((__add((__shl(v1_2e_i202205_2e_us_, __extract_element(__smear_i32<__vec16_i32>(1u), 0) )), k_2e_0206_2e_us_)), __smear_i32<__vec16_i32>(134217727u))), v1_2e_i202205_2e_us_);
  k_load67_plus1_2e_us_ = __add(k_2e_0206_2e_us_, __smear_i32<__vec16_i32>(1u));
  oldMask_26_test52_2e_us_and_mask_ = __signed_less_than_i32_and_mask(k_load67_plus1_2e_us_, __smear_i32<__vec16_i32>(512u), oldMask_26_test52207_2e_us_);
  internal_mask_26_function_mask56_any_2e_us_ = ((__any(oldMask_26_test52_2e_us_and_mask_))&1);
  if (internal_mask_26_function_mask56_any_2e_us_) {
    oldMask_26_test52207_2e_us___PHI = oldMask_26_test52_2e_us_and_mask_;   /* for PHI node */
    k_2e_0206_2e_us___PHI = k_load67_plus1_2e_us_;   /* for PHI node */
    v1_2e_i202205_2e_us___PHI = v1_2e_i_2e_us_;   /* for PHI node */
    goto for_loop46_2e_us_label;
  } else {
    v1_2e_i202_2e_lcssa_2e_us___PHI = v1_2e_i_2e_us_;   /* for PHI node */
    goto for_exit47_2e_us_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop46.us' */
for_exit47_2e_us_label: {
  v1_2e_i202_2e_lcssa_2e_us_ = v1_2e_i202_2e_lcssa_2e_us___PHI;
  j_load75_plus1_2e_us_ = __add(j_2e_0210_2e_us_, __smear_i32<__vec16_i32>(1u));
  oldMask_26_test_2e_us_and_mask_ = __signed_less_than_i32_and_mask(j_load75_plus1_2e_us_, __smear_i32<__vec16_i32>(4u), oldMask_26_test211_2e_us_);
  internal_mask_26_function_mask32_any_2e_us_ = ((__any(oldMask_26_test_2e_us_and_mask_))&1);
  if (internal_mask_26_function_mask32_any_2e_us_) {
    oldMask_26_test211_2e_us___PHI = oldMask_26_test_2e_us_and_mask_;   /* for PHI node */
    j_2e_0210_2e_us___PHI = j_load75_plus1_2e_us_;   /* for PHI node */
    v1_2e_i201209_2e_us___PHI = v1_2e_i202_2e_lcssa_2e_us_;   /* for PHI node */
    goto for_loop_2e_us_label;
  } else {
    goto foreach_reset_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop.us' */
for_loop_2e_lr_2e_ph_2e_us_label: {
  base_index_smear_ = __smear_i32<__vec16_i32>(base_index_);
  data_arr_load_offset_load193_2e_us_ = __gather_base_offsets64_i32((((uint8_t *)data_arr_)), 1u, ((__cast_zext(__vec16_i64 (), (__mul((__and((__add(base_index_smear_, __load<64>((const __vec16_i32  *)(VectorConstant0)))), __smear_i32<__vec16_i32>(134217727u))), __smear_i32<__vec16_i32>(4u)))))), __smear_i1<__vec16_i1>(1));
  oldMask_26_test211_2e_us___PHI = __smear_i1<__vec16_i1>(1);   /* for PHI node */
  j_2e_0210_2e_us___PHI = __setzero_i32<__vec16_i32>();   /* for PHI node */
  v1_2e_i201209_2e_us___PHI = data_arr_load_offset_load193_2e_us_;   /* for PHI node */
  goto for_loop_2e_us_label;

}
foreach_reset_label: {
  return;
}
}


static const int32_t __attribute__ ((aligned(64))) VectorConstant1[] = { 0u, 1u, 2u, 3u, 4u, 5u, 6u, 7u, 8u, 9u, 10u, 11u, 12u, 13u, 14u, 15u,  };

void simple(uint32_t *data_arr_, uint32_t *pkt_arr_, uint32_t base_index_) {
  bool internal_mask_26_function_mask32_any208_;
  uint8_t *ptr_;
  __vec16_i32 (*ptrcast_);
  __vec16_i1 oldMask_26_test211_2e_us_;
  __vec16_i1 oldMask_26_test211_2e_us___PHI;
  __vec16_i32 j_2e_0210_2e_us_;
  __vec16_i32 j_2e_0210_2e_us___PHI;
  __vec16_i32 v1_2e_i201209_2e_us_;
  __vec16_i32 v1_2e_i201209_2e_us___PHI;
  __vec16_i32 ptr_masked_load_2e_us_;
  bool internal_mask_26_function_mask56_any204_2e_us_;
  __vec16_i32 v1_2e_i202_2e_lcssa_2e_us_;
  __vec16_i32 v1_2e_i202_2e_lcssa_2e_us___PHI;
  __vec16_i32 j_load75_plus1_2e_us_;
  __vec16_i1 oldMask_26_test_2e_us_and_mask_;
  bool internal_mask_26_function_mask32_any_2e_us_;
  __vec16_i1 oldMask_26_test52207_2e_us_;
  __vec16_i1 oldMask_26_test52207_2e_us___PHI;
  __vec16_i32 k_2e_0206_2e_us_;
  __vec16_i32 k_2e_0206_2e_us___PHI;
  __vec16_i32 v1_2e_i202205_2e_us_;
  __vec16_i32 v1_2e_i202205_2e_us___PHI;
  __vec16_i32 v1_2e_i_2e_us_;
  __vec16_i32 k_load67_plus1_2e_us_;
  __vec16_i1 oldMask_26_test52_2e_us_and_mask_;
  bool internal_mask_26_function_mask56_any_2e_us_;
  __vec16_i32 base_index_smear_;
  __vec16_i32 data_arr_load_offset_load193_2e_us_;

  internal_mask_26_function_mask32_any208_ = ((__any(__smear_i1<__vec16_i1>(1)))&1);
  ptr_ = (&(((uint8_t *)pkt_arr_))[((int64_t )(((int64_t )(int32_t )(base_index_ << 2u))))]);
  ptrcast_ = ((__vec16_i32 (*))ptr_);
  if (internal_mask_26_function_mask32_any208_) {
    goto for_loop_2e_lr_2e_ph_2e_us_label;
  } else {
    goto foreach_reset_label;
  }

  do {     /* Syntactic loop 'for_loop.us' to make GCC happy */
for_loop_2e_us_label: {
  oldMask_26_test211_2e_us_ = oldMask_26_test211_2e_us___PHI;
  j_2e_0210_2e_us_ = j_2e_0210_2e_us___PHI;
  v1_2e_i201209_2e_us_ = v1_2e_i201209_2e_us___PHI;
  ptr_masked_load_2e_us_ = __masked_load_i32(ptr_, oldMask_26_test211_2e_us_);
  __masked_store_i32(ptrcast_, (__add(ptr_masked_load_2e_us_, v1_2e_i201209_2e_us_)), oldMask_26_test211_2e_us_);
  internal_mask_26_function_mask56_any204_2e_us_ = ((__any(oldMask_26_test211_2e_us_))&1);
  if (internal_mask_26_function_mask56_any204_2e_us_) {
    oldMask_26_test52207_2e_us___PHI = oldMask_26_test211_2e_us_;   /* for PHI node */
    k_2e_0206_2e_us___PHI = __setzero_i32<__vec16_i32>();   /* for PHI node */
    v1_2e_i202205_2e_us___PHI = v1_2e_i201209_2e_us_;   /* for PHI node */
    goto for_loop46_2e_us_label;
  } else {
    v1_2e_i202_2e_lcssa_2e_us___PHI = v1_2e_i201209_2e_us_;   /* for PHI node */
    goto for_exit47_2e_us_label;
  }

}
  do {     /* Syntactic loop 'for_loop46.us' to make GCC happy */
for_loop46_2e_us_label: {
  oldMask_26_test52207_2e_us_ = oldMask_26_test52207_2e_us___PHI;
  k_2e_0206_2e_us_ = k_2e_0206_2e_us___PHI;
  v1_2e_i202205_2e_us_ = v1_2e_i202205_2e_us___PHI;
  v1_2e_i_2e_us_ = __select(oldMask_26_test52207_2e_us_, (__and((__add((__shl(v1_2e_i202205_2e_us_, __extract_element(__smear_i32<__vec16_i32>(1u), 0) )), k_2e_0206_2e_us_)), __smear_i32<__vec16_i32>(134217727u))), v1_2e_i202205_2e_us_);
  k_load67_plus1_2e_us_ = __add(k_2e_0206_2e_us_, __smear_i32<__vec16_i32>(1u));
  oldMask_26_test52_2e_us_and_mask_ = __signed_less_than_i32_and_mask(k_load67_plus1_2e_us_, __smear_i32<__vec16_i32>(512u), oldMask_26_test52207_2e_us_);
  internal_mask_26_function_mask56_any_2e_us_ = ((__any(oldMask_26_test52_2e_us_and_mask_))&1);
  if (internal_mask_26_function_mask56_any_2e_us_) {
    oldMask_26_test52207_2e_us___PHI = oldMask_26_test52_2e_us_and_mask_;   /* for PHI node */
    k_2e_0206_2e_us___PHI = k_load67_plus1_2e_us_;   /* for PHI node */
    v1_2e_i202205_2e_us___PHI = v1_2e_i_2e_us_;   /* for PHI node */
    goto for_loop46_2e_us_label;
  } else {
    v1_2e_i202_2e_lcssa_2e_us___PHI = v1_2e_i_2e_us_;   /* for PHI node */
    goto for_exit47_2e_us_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop46.us' */
for_exit47_2e_us_label: {
  v1_2e_i202_2e_lcssa_2e_us_ = v1_2e_i202_2e_lcssa_2e_us___PHI;
  j_load75_plus1_2e_us_ = __add(j_2e_0210_2e_us_, __smear_i32<__vec16_i32>(1u));
  oldMask_26_test_2e_us_and_mask_ = __signed_less_than_i32_and_mask(j_load75_plus1_2e_us_, __smear_i32<__vec16_i32>(4u), oldMask_26_test211_2e_us_);
  internal_mask_26_function_mask32_any_2e_us_ = ((__any(oldMask_26_test_2e_us_and_mask_))&1);
  if (internal_mask_26_function_mask32_any_2e_us_) {
    oldMask_26_test211_2e_us___PHI = oldMask_26_test_2e_us_and_mask_;   /* for PHI node */
    j_2e_0210_2e_us___PHI = j_load75_plus1_2e_us_;   /* for PHI node */
    v1_2e_i201209_2e_us___PHI = v1_2e_i202_2e_lcssa_2e_us_;   /* for PHI node */
    goto for_loop_2e_us_label;
  } else {
    goto foreach_reset_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop.us' */
for_loop_2e_lr_2e_ph_2e_us_label: {
  base_index_smear_ = __smear_i32<__vec16_i32>(base_index_);
  data_arr_load_offset_load193_2e_us_ = __gather_base_offsets64_i32((((uint8_t *)data_arr_)), 1u, ((__cast_zext(__vec16_i64 (), (__mul((__and((__add(base_index_smear_, __load<64>((const __vec16_i32  *)(VectorConstant1)))), __smear_i32<__vec16_i32>(134217727u))), __smear_i32<__vec16_i32>(4u)))))), __smear_i1<__vec16_i1>(1));
  oldMask_26_test211_2e_us___PHI = __smear_i1<__vec16_i1>(1);   /* for PHI node */
  j_2e_0210_2e_us___PHI = __setzero_i32<__vec16_i32>();   /* for PHI node */
  v1_2e_i201209_2e_us___PHI = data_arr_load_offset_load193_2e_us_;   /* for PHI node */
  goto for_loop_2e_us_label;

}
foreach_reset_label: {
  return;
}
}

